æ ¹æ® [é˜¿é‡Œå®˜æ–¹ä»“åº“ QwenLM/Qwen2.5-VL](https://github.com/QwenLM/Qwen2.5-VL) çš„æœ€æ–°å†…å®¹ï¼Œ**ä½¿ç”¨è‡ªæœ‰å›¾æ–‡æ•°æ®å¾®è°ƒæœ¬åœ°çš„ Qwen2.5-VL-3B æ¨¡å‹**ï¼ˆLoRA/Q-LoRAï¼‰å¤§è‡´æµç¨‹å¦‚ä¸‹ï¼š

---

## âœ… å¾®è°ƒ Qwen2.5-VL-3B çš„å®Œæ•´æ­¥éª¤ï¼ˆåŸºäºå®˜æ–¹ä»“åº“ï¼‰

### ğŸŒŸ å‰ææ¡ä»¶

| é¡¹ç›®   | è¯´æ˜                                                        |
| ---- | --------------------------------------------------------- |
| æ¨¡å‹ç‰ˆæœ¬ | Qwen2.5-VL-3B                                             |
| å¾®è°ƒæ–¹å¼ | LoRA / Q-LoRAï¼ˆæ¨èï¼‰                                         |
| ç¯å¢ƒéœ€æ±‚ | è‡³å°‘ä¸€å¼  **24G+ æ˜¾å­˜** çš„ GPUï¼Œæˆ– 2Ã—16G                            |
| æ¨¡å‹æ¥æº | Hugging Face æˆ– ModelScope ä¸‹è½½ ckpt                         |
| æ¡†æ¶   | PyTorch + HuggingFace Transformers + peft + deepspeedï¼ˆå¯é€‰ï¼‰ |

---

### â‘  å…‹éš†å®˜æ–¹ä»“åº“ + å®‰è£…ä¾èµ–

```bash
git clone https://github.com/QwenLM/Qwen2.5-VL.git
cd Qwen2.5-VL
pip install -r requirements.txt
```

ä½ å¯èƒ½è¿˜éœ€é¢å¤–å®‰è£…ä»¥ä¸‹ï¼š

```bash
pip install accelerate peft bitsandbytes transformers datasets
```

---

### â‘¡ ä¸‹è½½æ¨¡å‹æƒé‡

Qwen2.5-VL-3Bï¼ˆBase æ¨¡å‹ï¼‰ä¸‹è½½åœ°å€ï¼š

* HuggingFace: [https://huggingface.co/Qwen/Qwen-VL-Chat-Int4](https://huggingface.co/Qwen/Qwen-VL-Chat-Int4)
* ModelScope: `qwen/Qwen-VL-Chat-Int4`

ä¸‹è½½åç›®å½•ç»“æ„ç±»ä¼¼äºï¼š

```
Qwen-VL-Chat-Int4/
â”œâ”€â”€ config.json
â”œâ”€â”€ pytorch_model.bin
â”œâ”€â”€ tokenizer/
â”œâ”€â”€ vision_encoder/
```

---

### â‘¢ å‡†å¤‡è‡ªæœ‰å›¾æ–‡æ•°æ®é›†

æ ¼å¼åº”ç¬¦åˆå®˜æ–¹æ¨èæ ¼å¼ï¼ˆåŸºäº `jsonl` çš„ Visual Instruction æ ¼å¼ï¼‰ï¼š

#### ç¤ºä¾‹ï¼š

```json
{
  "image": "your_image_name.jpg",
  "conversations": [
    {
      "from": "user",
      "value": "<img></img>è¯·æè¿°å›¾ç‰‡å†…å®¹ã€‚"
    },
    {
      "from": "assistant",
      "value": "è¿™æ˜¯ä¸€å¼ ..."
    }
  ]
}
```

#### æ•°æ®å‡†å¤‡æ³¨æ„ï¼š

* å›¾ç‰‡è·¯å¾„å­˜å‚¨åœ¨ä¸€ä¸ªæ–‡ä»¶å¤¹ï¼Œå¦‚ï¼š`data/images/`
* JSONL æ–‡ä»¶è·¯å¾„å¦‚ï¼š`data/my_dataset.jsonl`

ä½ å¯ä»¥ä½¿ç”¨ `tools/process_dataset.py` è¿›è¡Œé¢„å¤„ç†ï¼ˆè½¬ä¸º `.bin` æ ¼å¼ï¼‰ï¼Œä¹Ÿå¯ä»¥ç›´æ¥è®­ç»ƒã€‚

---

### â‘£ è¿è¡Œå¾®è°ƒè„šæœ¬

Qwen2.5-VL æä¾›äº†ä¸€ä¸ª `train.py` çš„æ ‡å‡†è®­ç»ƒå…¥å£ã€‚å®˜æ–¹æ”¯æŒ LoRA ä¸ Q-LoRAã€‚

#### å‘½ä»¤è¡Œå¾®è°ƒç¤ºä¾‹ï¼š

```bash
CUDA_VISIBLE_DEVICES=0 \
python train.py \
    --model_name_or_path /path/to/Qwen-VL-Chat-Int4 \
    --data_path data/my_dataset.jsonl \
    --image_folder data/images \
    --vision_tower openai/clip-vit-large-patch14 \
    --output_dir output/qwen-vl-lora \
    --model_max_length 2048 \
    --per_device_train_batch_size 1 \
    --gradient_accumulation_steps 4 \
    --num_train_epochs 3 \
    --lr_scheduler_type cosine \
    --learning_rate 2e-4 \
    --logging_steps 10 \
    --save_strategy "steps" \
    --save_steps 1000 \
    --save_total_limit 2 \
    --lora_target_modules all \
    --lora_r 8 \
    --lora_alpha 16 \
    --lora_dropout 0.05 \
    --bf16
```

---

### â‘¤ éªŒè¯å’Œæ¨ç†ï¼ˆinferenceï¼‰

ä½ å¯ä»¥ä½¿ç”¨ `scripts/infer.py` æˆ– notebook æ¥åŠ è½½è®­ç»ƒå¥½çš„ LoRA adapterï¼š

```python
from peft import PeftModel
model = AutoModelForCausalLM.from_pretrained(base_model_path)
model = PeftModel.from_pretrained(model, adapter_path)
```

æˆ–è€…ä½¿ç”¨ `AutoModelForCausalLM.from_pretrained(..., adapter_name=...)` è‡ªåŠ¨åŠ è½½ã€‚

---

## âœ… å¯é€‰å¢å¼ºé¡¹

| åŠŸèƒ½       | å»ºè®®                                                      |
| -------- | ------------------------------------------------------- |
| Q-LoRA   | å¼€å¯ `--load_in_4bit` å’Œ `bnb_4bit_compute_dtype=bf16` ç­‰å‚æ•° |
| å¤šå¡è®­ç»ƒ     | ä½¿ç”¨ deepspeed + accelerate é…ç½®                            |
| è‡ªå®šä¹‰å›¾åƒç¼–ç å™¨ | æ”¯æŒæ›¿æ¢ CLIP ä¸ºå…¶ä»– encoder                                   |
| å›¾æ–‡å¤šè½®é—®ç­”   | æ”¯æŒé•¿å¯¹è¯æ•°æ®é›†ç»“æ„                                              |

---

## âœ… æ€»ç»“

| æ­¥éª¤   | å·¥å…·/è¯´æ˜                                            |
| ---- | ------------------------------------------------ |
| å…‹éš†ä»“åº“ | `git clone https://github.com/QwenLM/Qwen2.5-VL` |
| å‡†å¤‡æ¨¡å‹ | ä¸‹è½½ Qwen2.5-VL-3Bï¼ˆå»ºè®® Int4 ç‰ˆï¼‰                      |
| æ„é€ æ•°æ® | æŒ‰ JSONL æ ¼å¼ç»„ç»‡å›¾æ–‡å¯¹                                  |
| å¯åŠ¨è®­ç»ƒ | ä½¿ç”¨ `train.py` + LoRA å‚æ•°                          |
| è¾“å‡ºæ¨¡å‹ | å­˜å‚¨åœ¨ `output/qwen-vl-lora/` ç›®å½•ä¸‹                   |

---

å¦‚ä½ å¸Œæœ›æˆ‘ä¸ºä½ ç”Ÿæˆå…·ä½“çš„è®­ç»ƒé…ç½®æ–‡ä»¶ï¼ˆ`json`/å‘½ä»¤è¡Œï¼‰ï¼Œæˆ–åŸºäºå·²æœ‰æ•°æ®æ ·ä¾‹ç”Ÿæˆ `jsonl` æ–‡ä»¶æ¨¡æ¿ï¼Œå¯ä»¥ç›´æ¥å‘æˆ‘å›¾æ–‡æ•°æ®æ ·æœ¬æˆ–æ•°æ®å­—æ®µè¯´æ˜ï¼Œæˆ‘æ¥å¸®ä½ è‡ªåŠ¨æ„å»ºè®­ç»ƒé›†ä¸è„šæœ¬ã€‚æ˜¯å¦éœ€è¦ï¼Ÿ
